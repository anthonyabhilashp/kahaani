import type { NextApiRequest, NextApiResponse } from "next";
import fs from "fs";
import path from "path";
import fetch from "node-fetch";
import ffmpeg from "fluent-ffmpeg";
import { supabaseAdmin } from "../../lib/supabaseAdmin";
import { JobLogger } from "../../lib/logger";
import { updateStoryMetadata } from "../../lib/updateStoryMetadata";
import * as Echogarden from "echogarden";
import { textToSSML } from "../../lib/ssmlHelper";

const ELEVENLABS_API = "https://api.elevenlabs.io/v1/text-to-speech";

function ffprobeAsync(filePath: string): Promise<ffmpeg.FfprobeData> {
  return new Promise((resolve, reject) => {
    ffmpeg.ffprobe(filePath, (err, data) => (err ? reject(err) : resolve(data)));
  });
}

export const config = { api: { bodyParser: { sizeLimit: "5mb" } } };

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  const { story_id, voice_id } = req.body;
  if (!story_id) return res.status(400).json({ error: "story_id is required" });

  let logger: JobLogger | null = null;

  try {
    logger = new JobLogger(story_id, "generate_all_audio");
    logger.log(`üéôÔ∏è Starting bulk audio generation for story: ${story_id}`);
    logger.log(`üì• Received voice_id from request: ${voice_id}`);

    const voiceId = voice_id || "21m00Tcm4TlvDq8ikWAM";
    logger.log(`üé§ Using voice_id: ${voiceId}`);

    // Use fixed defaults for voice parameters (same for all stories)
    const voiceStability = 0.4;
    const voiceSimilarity = 0.7;
    logger.log(`üé§ Voice settings: stability=${voiceStability}, similarity=${voiceSimilarity}`);

    // 1Ô∏è‚É£ Fetch all scenes for this story
    const { data: scenes, error: scenesErr } = await supabaseAdmin
      .from("scenes")
      .select("id, text, story_id, order")
      .eq("story_id", story_id)
      .order("order", { ascending: true });

    if (scenesErr) throw scenesErr;
    if (!scenes || scenes.length === 0) throw new Error("No scenes found for this story.");

    logger.log(`üìö Found ${scenes.length} scenes to generate audio for`);

    const updatedScenes = [];

    // 2Ô∏è‚É£ Generate audio for each scene
    for (let i = 0; i < scenes.length; i++) {
      const scene = scenes[i];
      logger.log(`\nüé¨ Processing scene ${i + 1}/${scenes.length} (ID: ${scene.id})`);
      logger.log(`üìñ Scene text: "${scene.text.substring(0, 50)}..."`);

      try {
        // 3Ô∏è‚É£ Convert text to SSML with intelligent pauses
        const isLastScene = i === scenes.length - 1;
        const ssmlText = textToSSML(scene.text, {
          sentencePause: 500, // 0.5s after sentences
          endPause: 800, // 0.8s at scene end
          commaPause: 300, // 0.3s after commas
          isLastScene: isLastScene, // 1.5s pause for final scene
        });
        logger.log(`üìù Using SSML for better narration flow${isLastScene ? ' (final scene)' : ''}`);
        logger.log(`üîç SSML preview: ${ssmlText.substring(0, 100)}...`);

        // 4Ô∏è‚É£ Generate audio with ElevenLabs
        logger.log(`üß† Generating TTS with ElevenLabs voice: ${voiceId}`);
        const ttsRes = await fetch(`${ELEVENLABS_API}/${voiceId}`, {
          method: "POST",
          headers: {
            "xi-api-key": process.env.ELEVENLABS_API_KEY!,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            text: ssmlText,
            model_id: "eleven_multilingual_v2",
            voice_settings: {
              stability: voiceStability,
              similarity_boost: voiceSimilarity
            },
            enable_ssml: true,
          }),
        });

        if (!ttsRes.ok) {
          const errorText = await ttsRes.text();
          throw new Error(`ElevenLabs API error: ${errorText}`);
        }

        const audioBuffer = Buffer.from(await ttsRes.arrayBuffer());

        // 5Ô∏è‚É£ Save locally
        const tempDir = path.join(process.cwd(), "tmp", scene.id);
        fs.mkdirSync(tempDir, { recursive: true });
        const audioPath = path.join(tempDir, `scene-${scene.id}.mp3`);
        fs.writeFileSync(audioPath, audioBuffer);

        // 6Ô∏è‚É£ Get duration
        const info = await ffprobeAsync(audioPath);
        const duration = info.format?.duration || 0;
        logger.log(`‚è± Audio duration: ${duration.toFixed(2)} seconds`);

        // 7Ô∏è‚É£ Generate word-level timestamps using forced alignment
        logger.log(`üîç Generating word-level timestamps with forced alignment...`);
        let wordTimestamps = null;
        try {
          const alignmentResult = await Echogarden.align(audioPath, scene.text, {
            engine: 'dtw',
            language: 'en',
          });

          wordTimestamps = alignmentResult.wordTimeline.map((entry: any) => ({
            word: entry.text,
            start: entry.startTime,
            end: entry.endTime
          }));

          logger.log(`‚úÖ Generated ${wordTimestamps.length} word timestamps`);
        } catch (alignErr: any) {
          logger.error(`‚ö†Ô∏è Word alignment failed for scene ${scene.id}, continuing without timestamps`, alignErr);
        }

        // 8Ô∏è‚É£ Delete old audio if exists
        const fileName = `scene-${scene.id}.mp3`;
        logger.log(`üóëÔ∏è Removing any existing audio file: ${fileName}`);
        await supabaseAdmin.storage.from("audio").remove([fileName]);

        // 9Ô∏è‚É£ Upload new audio to Supabase
        logger.log(`‚òÅÔ∏è Uploading new audio file: ${fileName}`);
        const { error: uploadErr } = await supabaseAdmin.storage
          .from("audio")
          .upload(fileName, fs.readFileSync(audioPath), {
            contentType: "audio/mpeg",
            upsert: false,
          });
        if (uploadErr) throw uploadErr;

        const audioUrl = `${process.env.NEXT_PUBLIC_SUPABASE_URL}/storage/v1/object/public/audio/${fileName}`;

        // üîü Update scene with audio URL, voice_id, duration, word timestamps
        const { error: updateErr } = await supabaseAdmin
          .from("scenes")
          .update({
            audio_url: audioUrl,
            voice_id: voiceId,
            duration: duration,
            word_timestamps: wordTimestamps,
            audio_generated_at: new Date().toISOString()
          })
          .eq("id", scene.id);

        if (updateErr) throw updateErr;

        logger.log(`‚úÖ Audio generated and saved for scene ${scene.id}`);

        updatedScenes.push({
          id: scene.id,
          order: scene.order,
          audio_url: audioUrl,
          duration: duration,
          voice_id: voiceId,
          word_timestamps: wordTimestamps
        });

      } catch (sceneErr: any) {
        logger.error(`‚ùå Failed to generate audio for scene ${scene.id}:`, sceneErr);
        // Continue with next scene instead of failing completely
        updatedScenes.push({
          id: scene.id,
          order: scene.order,
          error: sceneErr.message
        });
      }
    }

    logger.log(`\n‚úÖ Bulk audio generation completed. ${updatedScenes.filter(s => !('error' in s)).length}/${scenes.length} scenes successful`);

    // Update story metadata (duration and completion status)
    logger.log(`üìä Updating story metadata...`);
    await updateStoryMetadata(story_id);
    logger.log(`‚úÖ Story metadata updated`);

    res.status(200).json({
      story_id,
      voice_id: voiceId,
      total_scenes: scenes.length,
      successful_scenes: updatedScenes.filter(s => !('error' in s)).length,
      updated_scenes: updatedScenes
    });
  } catch (err: any) {
    if (logger) logger.error("‚ùå Error during bulk audio generation", err);
    res.status(500).json({ error: err.message });
  }
}
